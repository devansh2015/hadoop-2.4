<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
       <property>
                <name>dfs.namenode.name.dir</name>
                <value>file:///x/hadoop/hdfs/nn,file:///y/hadoop/hdfs/nn</value>
                <description>Comma separated list of paths. Use the list of directories from $DFS_NAME_DIR.
                 For example, /grid/hadoop/hdfs/nn,/x/hadoop/hdfs/nn.</description>
        </property> 
        <property>
                <name>dfs.datanode.data.dir</name>
                <value>/x/hadoop/hdfs/data, /y/hadoop/hdfs/data</value>
                <description>Comma separated list of paths. Use the list of directories from $DFS_DATA_DIR.
                For example, file:///grid/hadoop/hdfs/dn, file:///x/hadoop/hdfs/dn.</description>
        </property>
        <property>
                <name>dfs.replication</name>
                <value>3</value>
        </property>
        <property>
          <name>dfs.permissions</name>
            <value>false</value>
         </property>
	<property>
		<name>dfs.hosts.exclude</name>
		<value>/apache/hadoop/conf/dfs.exclude</value>
	</property>
        <property>
                <name>dfs.hosts.include</name>
                <value>/apache/hadoop/conf/dfs.include</value>
        </property>
	<property>
		<name>dfs.nameservices</name>
		<value>hacluster</value>
	</property>
	<property>
		<name>dfs.ha.namenodes.hacluster</name>
		<value>nn1,nn2</value>
	</property>
	<property>
		<name>dfs.namenode.rpc-address.hacluster.nn1</name>
		<value>nn1.hadoop.com:8020</value>
	</property>
	<property>
		<name>dfs.namenode.rpc-address.hacluster.nn2</name>
		<value>nn2.hadoop.com:8020</value>
	</property>
	<property>
                <name>dfs.namenode.http-address.hacluster.nn1</name>
                <value>nn1.hadoop.com:50070</value>
        </property>
	<property>
                <name>dfs.namenode.http-address.hacluster.nn2</name>
                <value>nn2.hadoop.com:50070</value>
        </property>
	<property>
		<name>dfs.namenode.shared.edits.dir</name>
		<value>qjournal://nn1.hadoop.com:8485;nn2.hadoop.com:8485;dn1.hadoop.com:8485/hacluster</value>
	</property>
	<property>
		<name>dfs.client.failover.proxy.provider.hacluster</name>
		<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
	</property>
	<property>
		<name>dfs.ha.fencing.methods</name>
		<value>sshfence</value>
	</property>	
	<property>
		<name>dfs.ha.fencing.ssh.private-key-files</name>
		<value>/home/hdfs/.ssh/id_rsa</value>
	</property>
	<property>
		<name>dfs.journalnode.edits.dir</name>
		<value>/x/hadoop/hdfs/journal</value>
	</property>
	<property>
		<name>dfs.ha.automatic-failover.enabled</name>
		<value>true</value>
	</property>
	<property>
		<name>ha.zookeeper.quorum</name>
		<value>nn1.hadoop.com:2181,nn2.hadoop.com:2181,dn1.hadoop.com:2181</value>
	</property>
</configuration>
